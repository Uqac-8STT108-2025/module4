---
title: "module4"
author: "GroupeB"
date: "`r Sys.Date()`"
output: html_document
---

```{r librairies_importation, include=FALSE}
#install.packages("ISLR")
library(tidyverse)
library("ISLR") #pour charger la librairie auto
```

### Exercice1 :

* Description des hypoth√®ses nulles :
Pour chaque variable, l'hypoth√®se nulle  stipule que cette qu'elle n'a aucun effet significatif sur les ventes. 
C'est √† dire : 

   - TV ; H_0 : " Les d√©penses en publicit√© t√©l√©vis√©e n'ont pas d'effet sur les ventes."
   
   - Radio ; H_0: "Les d√©penses en publicit√© radio n'ont pas d'effet sur les ventes."
   
   - Journaux ; H_0 : "Les d√©penses en publicit√© dans les journaux n'ont pas d'effet sur les ventes."
   
   - Intercept ; H_0 : "La variable de r√©f√©rence (elle n'est pas explicitement mentionn√©e dans le cadre de l'exercice) 
   est non n√©gligeable lorsque toutes les variables ind√©pendantes sont nulles."
   
   
   
  **Interpr√©tation des r√©sultats** :
  
Publicit√© t√©l√©vis√©e et radio : un effet significatif sur les ventes

Les valeurs p pour la TV (<0.0001) et la radio (<0.0001) sont tr√®s faibles.
Cela signifie que nous rejetons l'hypoth√®se nulle dans ces deux cas : il y a des preuves statistiques fortes que la publicit√© t√©l√©vis√©e et la publicit√© radio ont un effet significatif sur les ventes.
Publicit√© dans les journaux : pas d'effet significatif sur les ventes

La valeur p de la publicit√© dans les journaux (0.8599) est tr√®s √©lev√©e.
Cela signifie que nous ne rejetons pas l'hypoth√®se nulle : il n'y a pas de preuve statistique que la publicit√© dans les journaux ait un impact sur les ventes. Autrement dit, investir dans ce type de publicit√© ne semble pas influencer significativement les ventes.
Intercept : significatif

La valeur p associ√©e √† l'intercept est <0.0001, donc on rejette l'hypoth√®se nulle.
Cela sugg√®re qu'il existe un niveau de ventes de base m√™me en l'absence de d√©penses publicitaires.

Finalement, Les entreprises devraient privil√©gier la publicit√© t√©l√©vis√©e et radio pour augmenter les ventes, car ces deux formes de publicit√© ont un impact statistiquement significatif.

### Exercice 2:

#### a) Choix de la bonne r√©ponse : 

Nous avons $$\hat{y} = \beta _0\times + \beta _1\times GPA + \beta _2 \times QI
+ \beta _3\times Level + \beta _4\times(GPA\times QI) + \beta _5\times(GPA\times Level) + \epsilon$$


o√π :

- Level 1 est pour les dipl√¥m√©s du coll√®ge ; 

- Level 2 pour ceux du secondaire 

* Pour un dipl√¥m√© du Lyc√©e,(Level = 0), on a 

$$ \hat{y}_{Lycee} = \beta _0 +\beta _1 \times GPA + \beta _2 \times QI + \beta _4 \times GPA \times QI $$

* Pour un  dipl√¥m√© du coll√®ge = universitaire : (Level = 1) on a 

$$ \hat{y}_{col} = \beta _0 +\beta _1 \times GPA + \beta _2 \times QI + \beta _3 + \beta _4 \times (GPA \times QI) + \beta _5 \times GPA $$

* On √©value maintenant la diff√©rence pour pouvoir comparer :

$$ \hat{y}_{col} - \hat{y}_{lycee} = (beta _0 +\beta _1 \times GPA + \beta _2 \times QI + \beta _3 + \beta _4 \times (GPA \times QI) + \beta _5 \times GPA) - (\beta _0 +\beta _1 \times GPA + \beta _2 \times QI + \beta _4 \times GPA \times QI)$$ 

  $$\hat{y}_{col} - \hat{y}_{lycee} = \beta _3 + \beta _5 \times GPA$$
La bonne r√©ponse est 

iV ) Pour une valeur fixe de QI et de GPA, les dipl√¥m√©s universitaires gagnent en moyenne plus que les dipl√¥m√©s du secondaire, √† condition que la GPA soit suffisamment √©lev√©e.
Mais pour que √ßa marche, il faut bien s√ªr que $\beta_3 >0$

#### b) 
Pr√©diction  du salaire d‚Äôun dipl√¥m√© universitaire avec un QI de 110 et une moyenne cumulative de 4,0.

$$ \hat{y}_{col} = \beta _0 +\beta _1 \times GPA + \beta _2 \times QI + \beta _3 + \beta _4 \times (GPA \times QI) + \beta _5 \times GPA $$
$$ \hat{y}_{col} = \beta _0 +\beta _1 \times 4.5 + \beta _2 \times 110 + \beta _3 + \beta _4 \times (4.0 \times 110) + \beta _5 \times 4.0 $$
$$ \hat{y}_{col} = \beta _0 +4.0 \beta _1  + 110 \beta _2  + \beta _3 + 440.0 \beta _4  + 4 \beta _5  $$
Il manque les coefficients $\beta_i$ pour donner une pr√©diction numerique. 

#### c ) R√©ponse : 
Faux, ce n'est pas la valeur d'un coefficient qui d√©termine son interaction ou non, mais plut√¥t la p-value.

### Question 3 :

a ) On s'attend √† ce que la RSS du mod√®le cubique soit plus petit que celle du mod√®le lin√©aire sur les donn√©es
d'entrainement. Par ce que le mod√®le cubique a plus de param√®tres et capte plus de bruit, ce qui r√©duit significativement sa RSE.

b) regression lin√©aire : y_hat = a  + bX

Regression cubique : y_hat = a + bX + c X^2 + d X^3

Hypoth√®se nulle : c = d = 0

Si l'hypoth√®se nulle est rejet√© (p-value significativement petit), alors le mod√®le cubique 
s'ajuste mieux aux donn√©e.

c ) (pas sur !) En toutes circonstances, la regression quadratique capte plus de bruit que la regression lineaire.
Donc la RSE est necessairement plus petite si elle est calcul√©e sur les donn√©es test.

### Question 4 :

Question incomplete

### Question 5 :

D√©montrons que dans le cas d‚Äôune r√©gression lin√©aire simple, la droite des moindres carr√©s passe toujours par le point
moyen $G(\overline{x}, \overline{y})$.

L'√©quation d'une regression lin√©aire simple est donn√©e par $\hat{y} = a X + b + \epsilon$

o√π $$ b= \frac{\sum(x_i - \overline{x})(y_i - \overline{y})}{\sum(x_i - \overline{x})^2} $$ et 
$$b = \overline{y} - a \overline{x}$$
d√®s lors, $$a\overline{x} +b +\epsilon = a\overline{x} + \overline{y} - a \overline{x} \approx  \overline{y}  
 $$     cqfd.
 
### Question 6 
incomplet

## Pratique: 

### Exercice 1 

#### a) 

```{r regression-lineaire}
modele_lineaire <- lm(mpg ~ horsepower, data = Auto)
summary(modele_lineaire)
```

##### i )  
**p-value: < 2.2e-16 ** --> oui il existe une relation entre le pr√©dicteur et la r√©ponse ?

##### ii ) 
force de la relation entre le pr√©dicteur et la r√©ponse  : **R^2  0.6059** --> 60.59 % de la variabilit√© 
des pr√©dictions de mpg √† partir de horsepower sont expliqu√©es par le mod√®le.

##### iii ) 
Signe de la relation : horsepower = -0.157845, c-a-d $\beta_ 1 <0 --> $ les deux variables √©voluent en sens contraire.

##### iv ) 
mpg pr√©vu associ√© √† une puissance de 98 chevaux ?

```{r prediction-mpg}
predire_mpg <- function(horsepower) {
  b_0 <- 39.935861
  b_1 <- -0.157845
  return(b_0 + b_1 * horsepower)
}
predire_mpg(98)
```
La valeur pr√©dite pour 98 cheveaux est **mpg_hat = `r round(predire_mpg(98),2)`**

#### b)
graphique entre la r√©ponse (mpg) et le pr√©dicteur.

```{r graphique-modele-lineaire}
plot(Auto$horsepower, Auto$mpg, 
     main = "Relation entre MPG et Horsepower", 
     xlab = "Horsepower", 
     ylab = "MPG", 
     col = "blue")  
abline(modele_lineaire, col = "black",lwd = 3)  
legend("topright", legend = "Droite de r√©gression", col = "black", lwd = 3)

```

 v) Quels sont les intervalles de confiance et de pr√©diction √† 95 % associ√©s ?

#### c) 

```{r verifications-modele-lineaire }
# G√©n√©rer les diagnostics du mod√®le
par(mfrow = c(2, 2))  
plot(modele_lineaire)  
```
commentaires :

* La distribution des r√©sidus a une forme quadratique,, ce qui pose probl√®me, elle ne doit pas avoir 
une r√©partition perceptible

* Le diagramme Quantiles-quantile a une forme lineaire --> Les r√©sidus suivent une distribution normale



### Question 2 
Cette question implique l‚Äôutilisation d‚Äôune r√©gression lin√©aire multiple sur l‚Äôensemble de donn√©es Auto.

#### a)
Produisons une matrice de nuages de points qui inclut toutes les variables de l‚Äôensemble de donn√©es.

```{r nuage_points}
library(ISLR)
data(Auto) 
pairs(Auto, main = "Matrice de nuages de points pour Auto")
```

#### b)
Calculons la matrice des corr√©lations entre les variables √† l‚Äôaide de la fonction cor(). nous devions exclure la variable name qui est qualitative.

```{r matrice de correlation}
data(Auto)
#Extrait la variable "name"
Auto_numeric <- Auto[, -which(names(Auto) == "name")]

#Calculons la matrice des corr√©lations
cor_matrix <- cor(Auto_numeric)

print(round(cor_matrix, 2))
```
#### c) 
Utilisons la fonction lm() pour effectuer une r√©gression lin√©aire multiple avec mpg comme r√©ponse et toutes les autres variables sauf le nom comme pr√©dicteurs. Utilisez la fonction summary() pour imprimer les r√©sultats. Commentons le r√©sultat. Par exemple:

 i- Existe-t-il une relation entre les pr√©dicteurs et la r√©ponse ?

**p-value < 2.2e-16 pour le test F, ce qui indique confirment qu'il existe une forte relation entre les pr√©dicteurs choisis et mpg, permettant de mod√©liser efficacement la consommation de carburant des v√©hicules pr√©sents dans le jeu de donn√©es Auto.

```{r relation_predicteurs}
data(Auto)
modele_multiple <- lm(mpg ~ . - name, data = Auto)
summary(modele_multiple)
```

ii- Quels pr√©dicteurs semblent avoir une relation statistiquement significative avec la r√©ponse ?

Dans le mod√®le de r√©gression multiple de (i), on vas s√©lectionner les pr√©dicteurs qui pr√©sentent des p‚Äëvalues tr√®s faibles (inf√©rieures √† 0,05):
horsepower:p = 0,21
weight: p = 2e‚Äë16
year:p < 2e‚Äë16
origin:p= 0,013

iii-Que sugg√®re le coefficient de la variable ¬´ ann√©e ¬ª 

Le coefficient de la variable ¬´ann√©e¬ª est positif d'environ 0,75, ce qui sugg√®re qu'en moyenne, chaque ann√©e additionnelle est associ√©e √† une augmentation d'environ 0,75 mpg. Autrement dit, les v√©hicules plus r√©cents tendent √† afficher une meilleure efficacit√© √©nerg√©tique.



#### d)
Utilisons la fonction plot() pour produire des trac√©s de diagnostic de l‚Äôajustement de r√©gression lin√©aire. Commentez tous les probl√®mes que vous voyez avec l‚Äôajustement. 

Avec le mod√®le_simple

```{r modele_simple}
#pla√ßons les graphe 2 a 2
par(mfrow = c(2, 2))
#graphe
plot(modele_multiple)
```
* Les trac√©s r√©siduels sugg√®rent-ils des valeurs aberrantes inhabituellement importantes ? 

D'apr√®s les trac√©s de diagnostic d'ajustement g√©n√©r√©s notamment le graphique "Residuals vs Fitted" et le "Residuals vs Leverage", aucun point ne se d√©tache de mani√®re excessive.
les r√©sidus semblent globalement al√©atoires et bien r√©partis, sans valeurs aberrantes inhabituelles, et le graphique d'effet de levier ne signale pas d'observations avec un effet de levier exceptionnellement √©lev√©.

* Le graphique de l‚Äôeffet de levier identifie-t-il des observations pr√©sentant un effet de levier inhabituellement √©lev√© ?

le graphique de l'effet de levier (r√©sidus vs levier) ne r√©v√®le aucune observation se situant en dehors des limites habituelles, Aucun point ne pr√©sente un effet de levier anormalement.

#### e)
Utilisez les symboles * et : pour ajuster les mod√®les de r√©gression lin√©aire avec des effets d‚Äôinteraction. Certaines interactions semblent-elles statistiquement significatives ?

Mod√®le avec interaction entre horsepower et year.

le coefficient d'interaction est n√©gatif et statistiquement significatif car p-value < 0.05, cela sugg√®re que l'effet n√©gatif de horsepower sur mpg devient plus prononc√© pour des v√©hicules plus r√©cents.

le modele avec *

```{r r√©gression_lin√©aire}
modele_interaction <- lm(mpg ~ horsepower * year, data = Auto)
summary(modele_interaction)
```
le modele avec :

```{r regression_lin√©aire }
modele_interaction2 <- lm(mpg ~ horsepower : year, data = Auto)
summary(modele_interaction2)
```
#### f) 
Essayons quelques transformations diff√©rentes des variables, telles que log(X), sqrt(X), X*2 Commentons vos d√©couvertes.

Mod√®le original : Le mod√®le utilisant horsepower en l'√©tat fournit une relation significative n√©gative avec mpg.

```{r mod√®le_original}
#Mod√®le avec la variable originale
model_orig <- lm(mpg ~ horsepower, data = Auto)
summary(model_orig)
par(mfrow = c(2, 2))
plot(model_orig, main = "Mod√®le original")
```

Transformation log :L'utilisation de log(horsepower) lin√©arise la relation qui √©tait autrement curviligne dans le mod√®le original et montre une de l'ajustement.

```{r mod√®le_log(X)}
# Mod√®le avec log(horsepower)
model_log <- lm(mpg ~ log(horsepower), data = Auto)
summary(model_log)
par(mfrow = c(2, 2))
plot(model_log, main = "Mod√®le log(horsepower)")
```


Transformation racine carr√©e :Le mod√®le avec sqrt(horsepower) r√©duire l'impact des valeurs √©lev√©es, am√©liore la lin√©arit√© de la relation ce qui am√©liore la r√©partition des r√©sidus.

```{r mod√®le_sqrt}
# Mod√®le avec racine carr√©e de horsepower
model_sqrt <- lm(mpg ~ sqrt(horsepower), data = Auto)
summary(model_sqrt)
par(mfrow = c(2, 2))
plot(model_sqrt, main = "Mod√®le sqrt(horsepower)")
```

Transformation au carr√© :cette transformation ne semble g√©n√©ralement pas apporter une signification, et le terme peut m√™me rendre l'interpr√©tation plus complexe.

```{r mod√®le_carr√©e}
# Mod√®le avec horsepower au carr√©
model_sq <- lm(mpg ~ I(horsepower^2), data = Auto)
summary(model_sq)
par(mfrow = c(2, 2))
plot(model_sq, main = "Mod√®le horsepower^2")
```
### Question 3 

#### a)
Ajustons un mod√®le de r√©gression multiple pour pr√©dire les ¬´ Ventes ¬ª en utilisant ¬´ Prix ¬ª, ¬´ Urbain ¬ª et ¬´ √âtats-Unis ¬ª.

Nous allons ajuster le mod√®le de regression multiple utiliser la haut

```{r regression_multiple}
data(Carseats)
#Ajustons le modele utiliser la haut
modele_carseats <- lm(Sales ~ Price + Urban + US, data = Carseats)
summary(modele_carseats)
```

#### b)
Fournissons une interpr√©tation de chaque coefficient du mod√®le. Soyons prudent : certaines variables du mod√®le sont qualitatives !

Intercept: 13.04 Ce coefficient repr√©sente la valeur pr√©dite des ventes (Sales) pour le groupe de r√©f√©rence,les variables qualitatives sont cod√©es en variables indicatrices. 
l'interception correspond aux ventes moyennes pr√©dites pour un magasin situ√© dans une zone urbaine (Urban = Yes) hors des √âtats-Unis (US = No) avec un Prix √©gal √† 0.

Price: -0.054459 Pour chaque augmentation d'une unit√© du prix, en maintenant constantes toutes les autres variables, les ventes pr√©dites diminuent en moyenne de 0.054459 unit√©. Cela indique que le prix a un effet n√©gatif sur les ventes.

UrbanNo : -0.021916 Cette variable est un indicateur qui vaut 1 lorsque le magasin n'est pas situ√© en zone urbaine (Urban = No) et 0 lorsque le magasin est en zone urbaine (Urban = Yes). 
Le coefficient de -0.021916 sugg√®re que, toutes choses √©gales par ailleurs, les magasins situ√©s hors zone urbaine affichent des ventes pr√©dites inf√©rieures de 0.021916 unit√© par rapport aux magasins urbains. Cependant, cette diff√©rence n'est pas statistiquement significative car p-value ‚âà 0,936.

USYes : 1.200573 Cette variable indicatrice vaut 1 pour les magasins situ√©s aux √âtats‚ÄëUnis (US = Yes) et 0 pour ceux hors des √âtats‚ÄëUnis (US = Ne).
Le coefficient de 1.200573 indique qu'en moyenne, les magasins situ√©s aux √âtats-Unis affichent des ventes pr√©dites sup√©rieures de 1.200573 unit√© par rapport aux magasins non am√©ricains, toutes choses √©tant √©gales par ailleurs. Cet effet est tr√®s significatif car p-value < 2e‚Äë1).

```{r modele_carseats}
modele_carseats <- lm(Sales ~ Price + Urban + US, data = Carseats)
summary(modele_carseats)
```
#### c)
√âcrivons le mod√®le sous forme d‚Äô√©quation, en prenant soin de g√©rer correctement les variables qualitatives.

Sales= coef(Intercept) + coef(price)*price + coef(UrbanNo)*(Urban=no) + coef(USYes)*(US= yes).

 En application:
 
Sales = 13.04 +(-0.054459)*price + (-0.21916)*(Urban=No) + (1.200573)*(US=Yes)

NB:(Urban=No) vaut 1 si le magasin n'est pas en zone urbaine  sinon elle vaut 0 si (Urban = Yes).
-(US=YES) vaut 1 si le magasin est situ√© aux √âtats-Unis  sinon elle vaut 0 si (US = NO).

#### d)
Pour lequel des pr√©dicteurs pouvez-vous rejeter l‚Äôhypoth√®se nulle H‚ÇÄ : B‚±º = 0 ?

D'apr√®s le r√©sum√© du mod√®le sur l'ensemble de donn√©es Carseats price et us ont les plus faibles p-value, donc nous pouvons rejeter l'hypoth√®se nulle H‚ÇÄ : B‚±º = 0 pour les variables Price et US.

#### e)
Sur la base de notre r√©ponse √† la question pr√©c√©dente, ajustons un mod√®le plus petit qui utilise uniquement les pr√©dicteurs pour lesquels il existe des preuves d‚Äôassociation avec le r√©sultat.

Ajustons le mod√®le r√©duit en ne retenant que les pr√©dicteurs significatifs (Price et US) :

```{r predicteurs_association}
data(Carseats)
modele_carseats_small <- lm(Sales ~ Price + US, data = Carseats)
summary(modele_carseats_small)
```
#### f)
Dans quelle mesure les mod√®les (a) et (e) s‚Äôajustent-ils aux donn√©es ?

Les deux mod√®les s‚Äôajustent globalement bien aux donn√©es. Par exemple, dans le mod√®le (a) complet qui inclut Price, Urban et US.Meme en ajustant un mod√®le r√©duit (mod√®le(e)) ne retenant que Price et US (car Urban n'est pas significatif), on obtient des statistiques tr√®s proches

En gros la capacit√© pr√©dictive du mod√®le est quasiment la m√™me que l'on utilise ou non la variable Urban, ce qui confirme que seuls Price et US apportent une information significative pour expliquer Sales.

#### g) 
√Ä l‚Äôaide du mod√®le de (e), obtenons des intervalles de confiance de 95 % pour le(s) coefficient(s).

```{r intervall_confiance}
data(Carseats)
modele_carseats_small <- lm(Sales ~ Price + US, data = Carseats)
confint(modele_carseats_small, level = 0.95)
```

#### h) 
Existe-t-il des preuves de valeurs aberrantes ou d‚Äôobservations √† effet de levier √©lev√© dans le mod√®le de (e) ?

Le graphique "Residuals vs Fitted" montre que les r√©sidus sont bien r√©partis sans points extr√™mes.
Le "Normal QQ Plot" indique que les r√©sidus suivent globalement une distribution normale.

Le trac√© "Residuals vs Leverage" ne met pas en √©vidence d'observations avec un effet de levier

Dans l'ensemble, ces diagnostics ne r√©v√®lent pas de valeurs aberrantes ni d'observations avec un effet de levier excessif dans le mod√®le(e).

```{r graphe observation levier}
data(Carseats)
modele_carseats_small <- lm(Sales ~ Price + US, data = Carseats)
par(mfrow = c(2, 2))
plot(modele_carseats_small)
```

### Question 4

```{r generation-alleatoire-predicteur}
  set.seed(1)
  x <- rnorm(100)
  y <- 2 * x + rnorm(100)
```

#### a) 
Regression lineaire sans intercept de y sur x

```{r regression-sans-intercept-de-y-sur-x}
modele_lin_yx <- lm(y~x+0)
summary(modele_lin_yx)

```
* Estimation du coefficient :  **beta1_hat = 1.9939**,

*erreur type : **std = 0.1065**,

* statistique t : **t = 18.73**, 

*p-value : **p < 2e-16  **

* Commentaire : Il existe une correlation positive entre x et y. La p-value est extremement faible, ce qui signifie que nous rejetons l'hypothese nulle (beta1 = 0) ==> il y a une forte correlation lineaire entre ces deux variables, et 
le coefficient estim√© est significativement diff√©rent de 0.

#### b)
Regression lineaire sans intercept de x sur y

```{r regression-sans-intercept-de-x-sur-y}
modele_lin_xy <- lm(x~y+0)
summary(modele_lin_xy)
```
* Estimation du coefficient : **beta1_hat = 0.39111 **

* erreur type : **std = 0.02089**

* statistique t : **t = 18.73**

* p-value : **p <2e-16**

* Commentaire : Il existe une correlation positive entre x et y. La p-value est extremement faible, ce qui signifie que nous rejetons l'hypothese nulle (beta_1 = 0) ==> il y a une forte correlation lineaire entre ces deux variables, et 
le coefficient estim√© est significativement diff√©rent de 0.

#### c) 
Les deux relations ont la m√™me statistique t et la meme p-value. De plus, le produit des deux 
coefficient est √©gal √† R^2

R^2= 0.7798 et   beta1_xy * beta1-yx  = `r  round(modele_lin_xy$coefficients * modele_lin_yx$coefficients,4)`

#### d) 
Question manquante

#### e)
Question manquante

#### f)
Dans R, montrez que lorsque la r√©gression est effectu√©e avec un intercept la statistique t pour 
est la m√™me pour la r√©gression de y sur x que pour la r√©gression de x sur y.

* Regression lin√©aire de y sur x avec intercept : 

```{r regression-avec-intercept-de-y-sur-x, include=FALSE}
modele_lin_yx_intercep <- lm(y~x)
model_summary_yx <- summary(modele_lin_yx_intercep)
t_stat_yx <- model_summary_yx$coefficients["x", "t value"]
cat('la statistique du test est ' , t_stat_yx )
```
La statistique du test est : **t= `r t_stat_yx`**

** Regression lin√©aire de x sur y avec intercept : 

```{r regression-avec-intercept-de-x-sur-y, include= FALSE}
modele_lin_xy_intercep <- lm(x~y)
model_summary_xy <- summary(modele_lin_xy_intercep)
t_stat_xy <- model_summary_yx$coefficients["x", "t value"]
cat('la statistique du test est ' , t_stat_xy )

```
La statistique du test est : **t= `r t_stat_xy`**


###Question 5

#a-Dans quelles circonstances l‚Äôestimation du coefficient pour la r√©gression de sur est-elle la m√™me que l‚Äôestimation du coefficient pour la r√©gression de sur  ?

Dans une r√©gression lin√©aire sans intercept,l'estimation du coefficient pour la r√©gression de Y sur X est la m√™me que celle de la r√©gression de X sur Y uniquement lorsque la dispersion (la somme des carr√©s) de X est √©gale √† celle de Y.

#b-G√©n√©rons un exemple dans R avec observations dans lequel l‚Äôestimation du coefficient pour la r√©gression de sur est diff√©rente de l‚Äôestimation du coefficient pour la r√©gression de sur .

```{r exemple estimation du coefficient regression ou X diff Y}
#Exemple : Y = 2 * X (donc c = 2)
set.seed(123)
x <- rnorm(100)
y <- 2 * x

#La r√©gression sans intercept de Y sur X
model_y_on_x <- lm(y ~ 0 + x)
coef_y_on_x <- coef(model_y_on_x)

#La r√©gression sans intercept de X sur Y
model_x_on_y <- lm(x ~ 0 + y)
coef_x_on_y <- coef(model_x_on_y)

cat("Coefficient pour la r√©gression de Y sur X :", round(coef_y_on_x, 3), "\n")
cat("Coefficient pour la r√©gression de X sur Y :", round(coef_x_on_y, 3), "\n")
```

#c-G√©n√©rons un exemple dans R avec observations dans lequel l‚Äôestimation du coefficient pour la r√©gression de sur est la m√™me que l‚Äôestimation du coefficient pour la r√©gression de sur.

```{r exemple estimation du coefficient regression ou X,Y}
set.seed(123)
x <- rnorm(100)
y <- x  #Y est exactement √©gal √† X

#La r√©gression sans intercept de Y sur X
modele_Y_on_X <- lm(y ~ 0 + x)
coef_Y_on_X <- coef(modele_Y_on_X)

#La r√©gression sans intercept de X sur Y
modele_X_on_Y <- lm(x ~ 0 + y)
coef_X_on_Y <- coef(modele_X_on_Y)

cat("Coefficient pour la r√©gression de Y sur X :", round(coef_Y_on_X, 3), "\n")
cat("Coefficient pour la r√©gression de X sur Y :", round(coef_X_on_Y, 3), "\n")
```
###Question 6

#a)
Pour cr√©er un vecteur x de 100 observations tir√©es d'une distribution normale standard (N(0,1)) en assurant la reproductibilit√©, on vas utiliser
:
```{r vecteur x avec 100 observation}
set.seed(1)
x <- rnorm(100)
```

#b)
Pour cr√©er un vecteur eps de 100 observations issues d'une distribution normale avec une moyenne nulle et une variance de 0,25 (donc un √©cart type de 0,5), ont vas utiliser :

```{r vecteur eps avec 100 observation }
eps <- rnorm(100, mean = 0, sd = 0.5)
```

#c)
En utilisant x et eps, g√©n√©rons un vecteur y selon le mod√®le 
Quelle est la longueur du vecteur y ? 
la longueur est 100

Quelles sont les valeurs de et dans ce mod√®le lin√©aire ?
La valeur est 2
```{r vecteur y}
y <- 2 + 2 * x + eps
length(y)
```


#d)

Le graphique montre une relation lin√©aire positive entre x et y, ce qui est conforme au mod√®le g√©n√©rateur x=2+2ùë•+ùúñde plus aucun comportement non lin√©aire ni valeurs aberrantes marqu√©es ne semblent appara√Ætre, ce qui confirme que la relation entre x et y est bien lin√©aire
```{r graphe rtion entre X et Y}
plot(x, y, main = "Nuage de points : x vs y", xlab = "x", ylab = "y", pch = 19, col = "blue")
```

#e)
Le coefficient de l'interception est estim√© √† environ 2,03 et celui de x √† environ 1,98, ce qui est tr√®s proche des valeurs th√©oriques 2 et 2.
Les p‚Äëvalues extr√™mement faibles (p_value< 2e-16) indiquent que les deux coefficients sont tr√®s significatifs.
Le Multiple R carr√©e (environ 0.941) montre que le mod√®le explique une grande partie de la variance de y.
Ces r√©sultats confirment que le mod√®le am√©lior√© par moindres carr√©s reproduit correctement le mod√®le g√©n√©rateur x=2+2 x+œµ.

```{r mod√®le lineaire des moindres carr√©e }
set.seed(1)
x <- rnorm(100)
#La variance = 0.25, √©cart type = 0.5
eps <- rnorm(100, mean = 0, sd = 0.5) 
y <- 2 + 2 * x + eps

#L'ajustement du mod√®le lin√©aire
modele <- lm(y ~ x)
summary(modele)
```
#f)
le nuage de points, ajoute la ligne de r√©gression obtenue par les moindres carr√©s (mod√®le ajust√©) et la vraie ligne de r√©gression

```{r Nuage de points avec ligne des moindres carr√©s et vraie r√©gression}
set.seed(1)
x <- rnorm(100)
#L'√©cart type = 0.5 pour une variance de 0.25
eps <- rnorm(100, mean = 0, sd = 0.5)  
y <- 2 + 2 * x + eps

#La Cr√©ation du nuage de points
plot(x, y, main = "Nuage de points avec ligne des moindres carr√©s et vraie r√©gression",
     xlab = "x", ylab = "y", pch = 19, col = "gray")

#L'ajustement du mod√®le lin√©aire par moindres carr√©s
modele <- lm(y ~ x)

#On ajout de la ligne des moindres carr√©s (fitted model) en bleu)
abline(modele, col = "blue", lwd = 2)

#on ajout de la vraie ligne de r√©gression y = 2 + 2*x en rouge (trait pointill√©)
abline(a = 2, b = 2, col = "red", lwd = 2, lty = 2)

#on ajout d'une l√©gende
legend("topleft", legend = c("Ligne des moindres carr√©s", "R√©gression de la population"),
       col = c("blue", "red"), lty = c(1, 2), lwd = 2)
```
#g)

Explication:
le mod√®le g√©n√©rateur est x=2+2 x+œµ(donc lin√©aire) et l'ajout du terme x¬≤ n'a pas apporter d'am√©lioration significative.
Or dans le mod√®le polynomial, le coefficient associ√© √† I(x¬≤) permet d'√©valuer l'effet quadratique.
Si ce coefficient n'est pas statistiquement significatif (p-value > 0.05) et si le test d'ANOVA (comparaison entre le mod√®le lin√©aire et le mod√®le polynomial) ne montre pas une significative (p-value > 0.05), cela indique qu'il n'existe pas de preuves que le terme quadratique am√©liore l'ajustement du mod√®le.

```{r mod√®le de r√©gression polynomiale}
set.seed(1)
x <- rnorm(100)
eps <- rnorm(100, mean = 0, sd = 0.5)
y <- 2 + 2 * x + eps

#Le mod√®le lin√©aire simple
model_linear <- lm(y ~ x)

#Le mod√®le polynomiale (avec x et x^2)
model_poly <- lm(y ~ x + I(x^2))

#Le r√©sum√©s des mod√®les
summary(model_linear)
summary(model_poly)

#La comparaison formelle par un test d'anova
anova(model_linear, model_poly)
```
#h)
En diminuant la variance du terme d'erreur, on obtient des estimations plus pr√©cises et un meilleur ajustement global du mod√®le aux donn√©es, tout en confirmant que le mod√®le lin√©aire simple est bien adapt√© √† la structure de la relation simul√©e.

```{r processus de g√©n√©ration de donn√©es pour diminuer le bruit}
#(a) G√©n√©rons des donn√©es avec moins de bruit
set.seed(1)
x <- rnorm(100)                        
eps <- rnorm(100, mean = 0, sd = 0.25)   
y <- 2 + 2 * x + eps                   

#(b) V√©rification de la longueur y=100
length(y)  

#(c) Nuage de points
plot(x, y, main = "Nuage de points : x vs y (moins de bruit)",
     xlab = "x", ylab = "y", pch = 19, col = "blue")

#(d) Ajustement d'un mod√®le lin√©aire simple
model_linear <- lm(y ~ x)
summary(model_linear)

#(e) Ajoutons de la droite des moindres carr√©s et de la vraie ligne de r√©gression
plot(x, y, main = "x vs y : Moindres carr√©s vs Vraie r√©gression (moins de bruit)",
     xlab = "x", ylab = "y", pch = 19, col = "gray")
abline(model_linear, col = "blue", lwd = 2)
abline(a = 2, b = 2, col = "red", lwd = 2, lty = 2)
legend("topleft", legend = c("Mod√®le ajust√©", "Mod√®le vrai"),
       col = c("blue", "red"), lty = c(1, 2), lwd = 2)

#(f) Ajustement d'un mod√®le de r√©gression polynomiale (avec x et x^2) et comparaison
model_poly <- lm(y ~ x + I(x^2))
summary(model_poly)
anova(model_linear, model_poly)
```
#i)

Le fait d'augmenter la variance du terme d'erreur rend le mod√®le moins pr√©cis (erreurs standards plus √©lev√©es, R¬≤ plus faible), et le nuage de points montre une plus grande dispersion. Cependant, la relation lin√©aire reste clairement visible, et le mod√®le am√©lior√© par moindres carr√©s reste coh√©rent avec le mod√®le th√©orique x=2+2 x+œµ.

```{r  g√©n√®re des donn√©es avec plus de bruit}
#(a) G√©n√©rons des donn√©es avec plus de bruit
set.seed(1)
x <- rnorm(100)                       
eps <- rnorm(100, mean = 0, sd = 1)      
y <- 2 + 2 * x + eps                  

#(b) V√©rification de la longueur du vecteur y=100
length(y)  

#(c) Nuage de points entre x et y
plot(x, y, main = "Nuage de points : x vs y (plus de bruit)",
     xlab = "x", ylab = "y", pch = 19, col = "blue")

#(d) Ajustement du mod√®le lin√©aire simple et r√©sum√©
model_linear <- lm(y ~ x)
summary(model_linear)

#(e) Tracons les lignes : 
plot(x, y, main = "x vs y : Mod√®le ajust√© vs fonction vraie (plus de bruit)",
     xlab = "x", ylab = "y", pch = 19, col = "gray")
abline(model_linear, col = "blue", lwd = 2)
abline(a = 2, b = 2, col = "red", lwd = 2, lty = 2) 
legend("topleft", legend = c("Mod√®le ajust√©", "Mod√®le vrai"),
       col = c("blue", "red"), lty = c(1, 2), lwd = 2)

#(f) Ajustement du mod√®le de r√©gression polynomiale (incluant x et x^2)
model_poly <- lm(y ~ x + I(x^2))
summary(model_poly)

#Comparaison entre le mod√®le lin√©aire simple et le mod√®le polynomial
anova(model_linear, model_poly)
```

#j)

Explication:
Dans le jeu de donn√©es avec moins de bruit , la dispersion autour de la droite de r√©gression est plus faible. Par cons√©quent, les intervalles de confiance pour l'interception et le coefficient de x sont tr√®s √©troits, refl√©tant une incertitude moindre dans les estimations.

Dans le jeu de donn√©es avec plus de bruit , la variabilit√© des observations autour de la droite est plus √©lev√©e, ce qui conduit √† des erreurs standards plus grandes et √† des intervalles de confiance plus larges. Les intervalles sont ainsi plus √©tendus, traduisant une incertitude accumul√©e dans l'estimation des coefficients.

Dans le jeu de donn√©es original , les intervalles se situent entre ceux obtenus avec moins de bruit et ceux obtenus avec plus de bruit, ce qui est coh√©rent avec le fait que la variance du terme d'erreur influe directement sur la pr√©cision des estimations.

Ces observations montrent clairement comment la quantit√© de bruit (variance de l'erreur) affecte la pr√©cision (et donc la largeur des intervalles de confiance) des coefficients estim√©s dans un mod√®le de r√©gression lin√©aire.

```{r  intervalles de confiance}
set.seed(1)
#Le Jeu de donn√©es original
x <- rnorm(100)
eps_original <- rnorm(100, mean = 0, sd = 0.5)
y_original <- 2 + 2 * x + eps_original
model_original <- lm(y_original ~ x)
ci_original <- confint(model_original, level = 0.95)
print("Intervalle de confiance (jeu de donn√©es original) :")
print(round(ci_original, 3))

#Le Jeu de donn√©es avec plus de bruit
eps_bruit <- rnorm(100, mean = 0, sd = 1)
y_bruit <- 2 + 2 * x + eps_bruit
model_bruit <- lm(y_bruit ~ x)
ci_bruit <- confint(model_bruit, level = 0.95)
print("Intervalle de confiance (jeu de donn√©es avec plus de bruit) :")
print(round(ci_bruit, 3))

# Jeu de donn√©es avec moins de bruit (Œµ ~ N(0, 0.25¬≤))
eps_mbruit <- rnorm(100, mean = 0, sd = 0.25)
y_mbruit <- 2 + 2 * x + eps_mbruit
model_mbruit <- lm(y_mbruit ~ x)
ci_mbruit <- confint(model_mbruit, level = 0.95)
print("Intervalle de confiance (jeu de donn√©es avec moins de bruit) :")
print(round(ci_mbruit, 3))
```

